<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Forthcoming in Ratio Comments and suggestions welcome  Nader Shoaibi University of Indianapolis nadershb@gmail.com" />
  <title>Veritism and the Normativity of Logic </title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Veritism and the Normativity of Logic </h1>
<p class="author"><span>Forthcoming in <em>Ratio</em></span><br />
<span>Comments and suggestions welcome</span><br />
<br />
Nader Shoaibi<br />
University of Indianapolis<br />
<a href="nadershb@gmail.com">nadershb@gmail.com</a></p>
</header>
<p><strong><em>Keywords —</em></strong> coherence norms, aim of truth, epistemic normativity, epistemic utility theory</p>
<h1 id="introduction">Introduction</h1>
<p>Suppose your friend, Yaya, is looking for a certain key. She is told by a trusted friend that it is in either of the two drawers of her desk. She looks in the first drawer and doesn’t find it there. What should she believe? Well, at the very least it seems that she shouldn’t have the following combination of attitudes: believe that the key is in either of the two drawers, believe that it is not in the first, and believe that it is not in the second. And logical validity seems to play a crucial role in explaining why: that the key is in the second drawer follows by logical necessity from the key being in either of the two drawers and it’s not being in the first.</p>
<p>But this raises the question: Why should Yaya heed the advice of logic? What is it about logic that gives it the authority to tell Yaya what she should or shouldn’t believe? In short, what is the <em>source</em> of the normativity of logic? Call this the ‘source question’.</p>
<p>In this paper, I begin by identifying what I label the ‘extrinsic view’, which has a strong claim to being the standard view of the <em>source</em> of the normativity of logic (§<a href="#ext" data-reference-type="ref" data-reference="ext">2</a>). According to the extrinsic view, logic is to be understood in total isolation from our doxastic lives. On this view, logic can nevertheless have normative implications due to certain more fundamental normative facts about belief — that belief in some rough sense <em>aims at the truth</em>. My goal is to isolate two ways of making this rough idea more precise and argue that they both fail.</p>
<p>Here is the plan. After laying out the extrinsic view in §<a href="#ext" data-reference-type="ref" data-reference="ext">2</a>, I elaborate on the sense of the normativity of logic which is at issue throughout the paper in §<a href="#role" data-reference-type="ref" data-reference="role">3</a>. I call this the ‘response-guiding’ role of logic. I then identify two ways of making the basic idea behind the extrinsic view more precise in §<a href="#NGIA" data-reference-type="ref" data-reference="NGIA">4.1</a> and §<a href="#ND" data-reference-type="ref" data-reference="ND">4.2</a>. My primary focus will be on the latter, more promising account, according to which, irrationality of deductive incoherence is to be explained in terms of the notion of ‘dominance’ familiar from the literature on Probabilism. I argue that this account fails, because it <em>undergenerates</em> in the sense that it fails to identify all deductively incoherent states as irrational.</p>
<h1 id="ext">The Extrinsic View</h1>
<p>It’s easy nowadays to think that there is a straightforward answer to the source question. After all, the thought goes, didn’t Frege teach us that logic is the science of the <em>laws of truth</em>, not the laws of ‘taking-to-be-true’, i.e., contingent principles governing our human psychology? According to this line of thought, our understanding of logic is wholly independent of anything that might be going on with anyone’s beliefs. If there are normative implications of logic, this view holds, these should be understood on a par with the normative implications of other sciences like physics or chemistry: one ought to think in accordance with them, in so far as one aims to have true beliefs. Thus, just as a law of physics like <span class="math inline"><em>F</em> = <em>m</em><em>a</em></span> is not itself normative but can have normative implications for someone who wants to know what the force acting on an object of mass <span class="math inline"><em>m</em></span>, moving with acceleration <span class="math inline"><em>a</em></span> is, so it is with logic. While the valid schemata of logic are themselves normatively inert, they can have normative implications if one wants to gain true beliefs and avoid false ones.</p>
<p>A proponent of this view would say that all we need in order to make sense of the normativity of logic is, to use a phrase popularized by the widely-cited but unpublished <span class="citation" data-cites="macfarlane2004">MacFarlane (2004)</span>, a viable ‘bridge principle’ that connects logic, understood as an independent formal system, on the one hand, and normative claims about what we should or shouldn’t believe, on the other. Here is an example of a bridge principle:</p>
<blockquote>
<p>(Wo-) if <span class="math inline"><em>P</em>, <em>Q</em> ⊨ <em>R</em></span>, then you ought to see to it that if you believe <span class="math inline"><em>P</em></span> and <span class="math inline"><em>Q</em></span>, then you don’t disbelieve <span class="math inline"><em>R</em></span>, where to disbelieve <span class="math inline"><em>R</em></span> is to believe not-<span class="math inline"><em>R</em></span> and thus is inconsistent with suspending judgment about <span class="math inline"><em>R</em></span>.</p>
</blockquote>
<p>Note that (Wo-) is an example of what is sometimes called a ‘wide-scope’ norm (or rational requirement). This is because the normative operator — in this case ‘ought’ — takes wide-scope over the conditional. A wide-scope norm such as (Wo-) says that logic plays its normative role not by placing restrictions on individual attitudes, but by placing global restrictions on <em>sets</em> of doxastic attitudes. It thus doesn’t require holding any particular belief; rather it rules out certain combinations of attitudes.</p>
<p>While it is also possible to come up with ‘narrow-scope’ bridge principles, my focus here will be on wide-scope principles such as (Wo-). After all, ‘coherence’ is most naturally thought of as a matter of global, wide-scope requirements on sets of beliefs, which govern how beliefs stand in a network of other doxastic attitudes. My aim is to explore whether we can do this thought justice in our account of the normative role of logic.</p>
<p>From this sketch, we can identify two components of the view:</p>
<ol>
<li><p>Logical validity is to be defined independently of our doxastic lives.</p></li>
<li><p>Wide-scope coherence norms are vindicated by showing that following them contributes to some more fundamental doxastic good.</p></li>
</ol>
<p>Call this the ‘extrinsic view’ of the normativity of logic.</p>
<p>The most prominent version of the extrinsic view places a central emphasis on <em>truth</em>. According to this version, following <span class="citation" data-cites="tarski2002">Tarski (2002)</span>, logical validity is defined as the necessary preservation of truth in virtue of logical form. As for the second component, the idea is that logical norms have their normative implications in virtue of promoting truth as the most basic epistemic good. This latter assumption is sometimes referred to as ‘veritism’.</p>
<p>Despite the initial attractiveness of the extrinsic view, I will argue that the vertisit variety is not successful. My focus will be on the second component of the view. I will argue that even if we can define logical validity in completely independent terms from our doxastic lives, the veritist version of the extrinsic view has trouble fully accounting for the normative role of logic.</p>
<h1 id="role">Response-Guidance</h1>
<p>Before we begin, I should say more about what I understand by what I’ve been calling the ‘normative role of logic’. There are at least two paradigmatic cases which illustrate the specific idea I have in mind. By looking at these cases, my hope is that we can isolate a distinctive sense in which logic can play a normative role.</p>
<p>The first is <em>first-personal</em> deliberation. The original example involving Yaya is an instance of such a case. When Yaya wonders about where the key is, it seems that the logical relation between her current and possible beliefs plays a crucial role. In particular, it seems that logic can tell her that she shouldn’t hold on to her beliefs and also believe that the key isn’t in the drawer. This manifests itself in Yaya’s resistance to believe that the key isn’t in the drawer, and her correctly pointing out the logical relations if there is a question about her response. In this way, we might say that logic helps to <em>guide</em> Yaya’s deliberation about what to believe.</p>
<p>It’s important to note that there is nothing in this idea that rules out something getting the way of Yaya reasoning correctly: perhaps she is distracted or just not paying attention. In such cases, she would not be so guided and to that extent we might say that there is a defect in her belief system. But in cases where there are no such defects, logic seems to play a distinctive normative role in guiding her in her deliberations about what to believe.</p>
<p>It seems plausible to say that logic plays its response-guiding role through Yaya’s ‘grasp’ of the logical relations. We must be careful, however, not to invite a charge of over-intellectualization. To be sure, what the grasp of the logical relations consists in cannot amount to an <em>explicit</em> belief that one holds. For, in that case, the kind of explanation that I have in mind would not be available in most cases. For one thing, most people have no formal education in logic, and even if they do they don’t seem to exploit it in their ordinary deliberation about what to believe. For another, if we assume that the grasp of the principles requires an explicit belief, then in cases where one is distracted or just doesn’t see the logical relation or its relevance, it would seem that one would not count as grasping. But one’s being distracted or inattentive is no reason to think that logical norms don’t have application. The idea behind requiring a ‘grasp’ of the logical principles, then, should be construed in a way that make it possible for one to grasp and yet fail to conform to the norms. We might hope to achieve this by developing an account according to which the grasp amounts to some kind of <em>implicit</em> belief, which would then make the normative explanation that I have in mind possible.</p>
<p>The other paradigmatic case which illustrates the response-guiding role of logic is what we might label ‘constructive <em>third-personal</em> advice’. Suppose despite seeing that the key isn’t in the first drawer and having been told by a trusted friend that it is in either of the two drawers, Yaya still wonders where to look for the key. Observing Yaya, one can advise her to look in the second drawer. But notice that one can do so in one of two ways: either because one knows that the key is in the second drawer (by inference or observation); or because one knows that the key is in the second drawer <em>and</em> that Yaya is in a position to realize this. It is the second of these two ways which I am calling constructive advice. In such cases, one takes the advisee to have everything she needs in order to realize where the key is. Thus, for instance, one can tell her: “Yaya, didn’t you just look in the first drawer? And isn’t it true that if it’s not there, it has to be in the second drawer? <span class="math inline">…</span> Don’t you think that you should look in the second drawer?”</p>
<p>I call these cases of ‘<em>constructive</em> advice’, because the advice is given with the perspective of the agent in mind; the adviser tells the advisee what to believe given what <em>she</em> is in a position to know. In this way, this kind of advice is constructive in that it is typically meant to help the advisee see the right conclusion rather than revealing the conclusion without an accompanied rationale.</p>
<p>I’m going to assume that these cases are sufficient to illustrate the basic idea of response-guiding role. In the next two sections, I argue that <em>if</em> logic plays this kind of role, then the variations of the extrinsic view which I will isolate must be rejected because they cannot account for this role. Before getting to the argument, however, there might be some reservation about the antecedent of that conditional, namely, that logic does play any such role. So, allow me to briefly say a few words about that.</p>
<p>One might suggest that the ‘normative’ role that logic plays is, to use a phrase used by <span class="citation" data-cites="kolodny2005">Kolodny (2005)</span>, merely classificatory, helping us to categorize beliefs or constellations thereof as good or bad. On this view, logic gives us a set of norms or standards by which we can evaluate or assess beliefs or bits of reasoning from a third-personal perspective. A quick example helps to illustrate the idea of classificatory norms. Consider a toaster. Arguably, it is possible to derive what it is to be a good toaster from the function of a toaster, and from this we can construct ought-claims about toasters: that, for instance, toasters ought to toast bread. Obviously, however, there is no suggestion that these ought claims figure in any way in the operation of the toasters or, even more absurdly, that they can be used to give toasters constructive advice.</p>
<p>I don’t want to deny that logic may play a classificatory role as this suggestion proposes: logic does seem to provide us with standards of evaluation according to which we might assess and criticize each other and constellations of beliefs, assertions, etc. However, what I am keen on pressing here is that, as the cases above illustrate, there seems to be more to the normative role that logic plays, and my hope is to explore what this idea would entail if we took it seriously.</p>
<h1 id="explaining-the-normativity">Explaining the Normativity</h1>
<h2 id="NGIA">Take 1 - Guaranteed Inaccuracy</h2>
<p>So far we have seen that the extrinsic view wants to explain the normativity of a structural deductive norm such as (Wo-) in terms of the broad aim of truth for belief. But how exactly is that account supposed to go? In this and the next sections, I will isolate two ways of making that rough idea more precise and argue that neither can account for the response-guiding role of logic.</p>
<p>As a reminder, here is what (Wo-) says:</p>
<blockquote>
<p>(Wo-) If <span class="math inline"><em>P</em>, <em>Q</em> ⊨ <em>R</em></span>, then you ought to see to it that if you believe <span class="math inline"><em>P</em></span> and <span class="math inline"><em>Q</em></span>, then you don’t disbelieve <span class="math inline"><em>R</em></span>.</p>
</blockquote>
<p>For ease of presentation, I proceed as if the widely accepted (Wo-) is the correct bridge principle. My argument in the following sections, however, doesn’t depend on this assumption. What’s required is that the correct bridge principle be a wide-scope deductive norm which rules out a combination of attitudes as <em>all things considered</em> irrational.<sup>,</sup></p>
<p>(Wo-) rules out being in the following doxastic state: believing the premises of a valid argument while disbelieving the conclusion of a valid argument. Let us use the term ‘inaccurate attitude’ for either a belief in a falsehood or a disbelief in a truth. The first way of making the extrinsic view more precise begins with the observations that the state ruled out by (Wo-) is <em>guaranteed</em> to involve at least one inaccurate attitude. Someone who believes the premises and disbelieves the conclusion of a valid argument cannot possibly get everything right about the world, <em>no matter how the world actually is</em>. And this is something that one can know <em>a priori</em> without any concern about how the world actually is.</p>
<p>According to the first way of making the extrinsic view more precise, then, we can get a vindication of (Wo-) if we assume the following principle of doxastic rationality:</p>
<blockquote>
<p><span class="smallcaps">No Guaranteed Inaccurate Attitude</span> (NGIA): A state that is guaranteed to involve an inaccurate attitude is irrational.</p>
</blockquote>
<p>Unfortunately, however, NGIA is simply too strong. For there are familiar contexts in which one can rationally hold attitudes which are guaranteed to be inaccurate. The most famous cases of this phenomenon are the so-called Preface and Lottery Paradoxes.</p>
<p>Let us focus on the Preface. Consider a scientist who does some careful fieldwork and writes a book with her findings, endorsing everything she writes in the book. However, reflecting on her work in the preface of the book, as any responsible scientist would admit, she claims that at least one of the things that she says in the book is false. Thus, she explicitly endorses the negation of the conjunction of the things that she already endorses in the book. Now, supposing that her endorsements are true expressions of her full beliefs, she is guaranteed to have a false belief. And yet it appears that there is nothing irrational about what she does.</p>
<p>I think that the Preface is enough to show that NGIA is false. In fact, one might be inclined to think that it undermines the very idea of deductive coherence norms, since it shows that a generalized version of (Wo-) with many premises cannot be true.</p>
<p>It might thus be suggested that NGIA should be restricted to apply only to arguments with a few (say, less than 3) premises. This, however, would seem to be an <em>ad hoc</em> restriction as there doesn’t seem to be any independent reason to accept it. And, in any case, as we shall see in the next section, the second attempt at making the extrinsic view more precise has an elegant way of building this restriction in.</p>
<h2 id="ND">Take 2 - Dominance</h2>
<p>This brings us to the second, more promising attempt at making the extrinsic view more precise. The basic idea is this: Instead of identifying irrational states by appeal to some property of an individual state, we can have a <em>comparative</em> principle of rationality which identifies an irrational state by comparing it to other states that one might be in with respect to how well they accurately represent the world. A natural way of developing this is to say that rationality minimally requires something like avoiding a state that is guaranteed to be worse off than some other state one can be in.</p>
<p>Epistemic Utility Theory (EUT) gives us the tools to formulate this sketch more precisely. According to EUT, we can assign ‘utilities’ or ‘scores’ to the attitudes that we take towards a proposition as a function of whether the proposition is true or false. Because this is a version of veritism, these utilities are functions of the truth value of a given proposition. A utility function (<span class="math inline"><em>e</em><em>u</em></span>) maps the truth value of a proposition and the agent’s doxastic attitude toward that proposition (belief, disbelief, or suspension) to one of the three values for getting the facts right (<span class="math inline"><em>R</em></span>), wrong (<span class="math inline"> − <em>W</em></span>), or neither (<span class="math inline">0</span>): <span class="math inline"><em>e</em><em>u</em> : {<em>t</em>, <em>f</em>} × {<em>B</em>, <em>D</em>, <em>S</em>} → {<em>R</em>,  − <em>W</em>, 0}</span>. Plausibly the function should be defined such that true beliefs and false disbeliefs (i.e., accurate attitudes) have the same positive value, namely, <span class="math inline"><em>R</em></span>; suspension of belief gets a value of <span class="math inline">0</span> no matter what the truth value; and, false beliefs and true disbeliefs (i.e., inaccurate attitudes) have the same disvalue, namely, <span class="math inline"> − <em>W</em></span>. <br /><span class="math display">$$\begin{cases}
eu(t, B) = eu(f, D) = R\\
eu(t, S) = eu(f,S) = 0\\
eu(f, B) = eu(t,D) = -W
\end{cases}$$</span><br /> A doxastic state, as before, is a set of doxastic attitudes (belief, disbelief, or suspension). We can represent this with a function (a belief function) that takes the set of propositions which the agent entertains to the set of our three doxastic attitudes: <span class="math inline">{<em>B</em>, <em>D</em>, <em>S</em>}</span>. Using the above utility function, then, we can define an additive function that sums the utilities of all the attitudes in a state for any given possible world to generate an overall score for the state. This gives us a precise measure with which to compare doxastic states.</p>
<p>Given this machinery, let’s look at a simple example. Suppose <span class="math inline"><em>P</em></span> entails <span class="math inline"><em>Q</em></span>. Looking at the truth table for these two sentences, we have three possible truth value assignments. Since there are three possible attitudes — belief, suspension, and disbelief — there are 9 different states one can be in with respect to <span class="math inline"><em>P</em></span> and <span class="math inline"><em>Q</em></span>. Let us focus on the case of the combination that (Wo-) rules out, namely, to believe <span class="math inline"><em>P</em></span> and disbelieve <span class="math inline"><em>Q</em></span>. Call this state <span class="math inline"><em>s</em></span>. We have the following table for the utilities in each of the possible worlds: <br /><span class="math display">$$\begin{array}{c|c||c|l}
P &amp; Q &amp; s&amp; s^*\\
\hline
t &amp; t &amp; R-W&amp; 0\\
f &amp; t &amp; -W-W&amp; 0\\
f &amp; f &amp; -W+R&amp; 0\\
\end{array}$$</span><br /></p>
<p>Now given two fairly innocuous assumptions we can see why we should see to it that we are not in <span class="math inline"><em>s</em></span> as (Wo-) recommends: First, a weak conservatism about epistemic value: <span class="math inline"><em>R</em> &lt; <em>W</em></span>. This says that the disvalue of getting things wrong outweighs the value of getting things right. Intuitively, weak conservatism errs on the side of avoiding getting things wrong since, according to conservatism, that’s more costly than the benefits of getting things right.</p>
<p>The second assumption we need in order to vindicate (Wo-) is the following plausible principle of rationality:</p>
<blockquote>
<p><span class="smallcaps">No Strict Dominance</span> (ND): A state that is <em>strictly dominated</em> by another state the agent can switch to is irrational; where the notion of strict domination is defined as follows: Some state <span class="math inline"><em>x</em></span> is strictly dominated by another state <span class="math inline"><em>x</em>′</span> if and only if one can do better in every possible world by switching to <span class="math inline"><em>x</em>′</span>.</p>
</blockquote>
<p>With the first assumption in place, we can see that the utility assigned to state <span class="math inline"><em>s</em></span> will be negative at every possible world. But that would mean that <span class="math inline"><em>s</em></span> is strictly dominated by the state of suspension of belief on both propositions, no matter what. For this state (call it <span class="math inline"><em>s</em><sup>*</sup></span>) gets the value of suspension which is always <span class="math inline">0</span> in every possible world. Thus, the agent would be doing better with respect to the utility score in every possible world if she suspends her belief in both <span class="math inline"><em>P</em></span> and <span class="math inline"><em>Q</em></span>. From the second assumption, it follows that <span class="math inline"><em>s</em></span> is an irrational state to be in. Thus, we have a vindication of (Wo-) in the single-premise case: To be in the state that (Wo-) rules out, namely, to believe <span class="math inline"><em>P</em></span> and disbelieve <span class="math inline"><em>Q</em></span> is to be in a state in which one is <em>guaranteed</em> to do worse with respect to the utility score than some other state.</p>
<p>We thus seem to have a position which the proponent of the extrinsic view can happily occupy. When we deliberate about what to believe or when we try to give constructive advice, we must make sure to avoid the state of believing the premises of a valid argument and disbelieving the conclusion, because there is some other state one can adopt, regardless of how the world actually is, which does better with respect to accurately representing the world.</p>
<p>Note that because ND is weaker than NGIA it can handle the Preface cases with no problem. ND counts a state of believing the premises of a valid argument and disbelieving its conclusion as irrational only if the disvalue of getting things wrong outweighs the sum of the values of getting things right. We saw this in the form of the assumption that <span class="math inline"><em>R</em> &lt; <em>W</em></span> in the simple case of a single-premise argument. When we move from the single to multi-premise cases, the requirement would be <span class="math inline"><em>n</em><em>R</em> &lt; <em>W</em></span>, where <span class="math inline"><em>n</em></span> is the number of premises involved. What this means is that once <span class="math inline"><em>n</em></span> is large enough, as, for instance, in Preface cases, the condition <span class="math inline"><em>n</em><em>R</em> &lt; <em>W</em></span> ceases to hold and so ND would not count the state of believing the premises and disbelieving the conclusion as irrational. So, ND manages to vindicate (Wo-) (assuming <span class="math inline">2<em>R</em> &lt; <em>W</em></span>, since (Wo-) is formulated for 2 premises), without vindicating the generalized multi-premise version, which, as we have seen, would be implausible in light of the Preface cases.</p>
<p>I shall argue, however, that ND is <em>too</em> weak, because even in 2-premise cases (and assuming <span class="math inline">2<em>R</em> &lt; <em>W</em></span>), it fails to count all cases of deductive incoherence as irrational. As we go through the argument, it is helpful to have a concrete case in mind. So, let’s consider Yaya’s case again. According to our utility theoretic machinery, Yaya, who believes that the key is in one of the two drawers of her desk and that it’s not in the first while disbelieving that it’s in the second (call this state <span class="math inline"><em>s</em><sub>1</sub></span>) could switch to another state which is <em>guaranteed</em> to be better no matter how thing turn out to be. This is the state (call is <span class="math inline"><em>s</em><sub>0</sub></span>) where she suspends judgment on all the propositions in the argument. Since, given ND, being in <span class="math inline"><em>s</em><sub>1</sub></span> is irrational, Yaya ought to see to it that she’s not in it.</p>
<p>Now, the first thing to note is that for this result to hold <span class="math inline"><em>s</em><sub>0</sub></span> and <span class="math inline"><em>s</em><sub>1</sub></span> would have to be defined over <em>the same set of propositions</em>, since otherwise <span class="math inline"><em>s</em><sub>1</sub></span> could accumulate positive values — at least in some worlds — over the propositions which <span class="math inline"><em>s</em><sub>0</sub></span> doesn’t range over, in which case the scales would tip in favor of <span class="math inline"><em>s</em><sub>1</sub></span> in those worlds and so it would not be dominated by <span class="math inline"><em>s</em><sub>0</sub></span>.</p>
<p>So, our starting point in the story about why a state like <span class="math inline"><em>s</em><sub>1</sub></span> (state of believing the premises of a 2-premise valid argument, and disbelieving its conclusion) is irrational would have to be:</p>
<ul>
<li><p>There is a state, <span class="math inline"><em>s</em><sub>0</sub></span>, defined over the same set of propositions which is guaranteed to do better than <span class="math inline"><em>s</em><sub>1</sub></span>.</p></li>
</ul>
<p>Together with:</p>
<ul>
<li><p>If there is a state defined over the same set of propositions the agent can switch to which is guaranteed to do better than <span class="math inline"><em>s</em><sub>1</sub></span>, then <span class="math inline"><em>s</em><sub>1</sub></span> is irrational.</p></li>
</ul>
<p>This seems to entail:</p>
<ul>
<li><p><span class="math inline"><em>s</em><sub>1</sub></span> is irrational.</p></li>
</ul>
<p>The problem is that for this argument to work we need something stronger than (a). In particular, what we need is:</p>
<ul>
<li><p>There is a state, <span class="math inline"><em>s</em><sub>0</sub></span>, defined over the same set of propositions that <em>the agent can switch to</em> which is guaranteed to do better than <span class="math inline"><em>s</em><sub>1</sub></span>.</p></li>
</ul>
<p>But there is reason to doubt that (a’) is true. As I originally described the case, Yaya comes to have her belief that the key is in either of the two drawers through the testimony of a trusted friend. But notice that if Yaya suspends judgment on the propositions involved in the argument — in particular, that the key is in either of the two drawers —, then there would have to be other beliefs of hers that need to be adjusted: for instance, her belief that her friend’s testimony is sufficiently strong. But in that case her new state would not be <span class="math inline"><em>s</em><sub>0</sub></span>, since it is not exactly like <span class="math inline"><em>s</em><sub>1</sub></span> on the propositions other than those involved in the argument.</p>
<p>And this seems to be true of just about any belief: For any belief, there are some attitudes that she could not rationally have if she suspends judgment on that belief.<sup>,</sup> If so, then we can’t assume that the state that is identical to one’s original state but suspends judgment on <em>only</em> the three propositions in the argument is necessarily one which one can switch to. That’s because suspending a given belief can have repercussions for other attitudes that one has, which would make it impossible to suspend on only the propositions involved in the argument and leave everything else intact.</p>
<p>The upshot is this. To show that a given state is irrational by appeal to ND, one must find a state, which (1) is defined over the same set of propositions, (2) suspends judgment on the propositions involved in the argument, (3) assigns exactly the same attitudes to every other proposition, and (4) is available for the agent to switch to. While we can certainly find a state that satisfies 1–3, there is no reason to expect that such a state is guaranteed to be among those that are available for the agent to switch to. Since, according to ND, we can only say that the state is irrational if we can find a dominant state which the agent can switch to, this implies that there is no guarantee that all deductively incoherent states are counted as irrational.</p>
<p>It might be tempting to try to salvage the dominance argument by strengthening ND. One might thus propose dropping the requirement that the strictly dominant state be <em>available</em> to the agent to switch to:</p>
<blockquote>
<p>(ND’): If there is a state defined over the same set of propositions which is guaranteed to do better than <span class="math inline"><em>S</em><sub>1</sub></span>, then <span class="math inline"><em>S</em><sub>1</sub></span> is irrational.</p>
</blockquote>
<p>Unfortunately, however, this proposal fails to capture the appropriate sense of normativity. Recall that the target here is not merely a classificatory notion of normativity, but a response-guiding notion in the sense illustrated in cases of deliberation and constructive advice in §<a href="#role" data-reference-type="ref" data-reference="role">3</a>. This seems to make the availability requirement indispensable. After all, according to the dominance account, the explanation of why one should avoid an inconsistent state is that being in that state is strictly dominated by another. But unless the dominant state is available for the agent to switch to, it is hard to see how this could enter into her deliberation about what to believe.</p>
<p>An analogy helps to clarify this point. Suppose I want to strip a wire. Let’s assume that it’s always better to use a wire stripper than to use one’s teeth to strip a wire (which, let’s assume, is a method I should never use). But suppose I don’t have a wire stripper. What should I do? Does the fact that using a wire stripper is better than using my teeth show that I shouldn’t use my teeth? It seems clear to me that it does not. I want to know how to strip this wire now, and knowing that there is some better way which, as it happens, isn’t available to me, doesn’t help me one bit in deciding what to do. Of course, this is not to say that, under the circumstances, stripping the wire using my teeth <em>is</em> a good idea. There may indeed be very good reasons in general –– in this case, having to do with my dental hygiene –– not to use my teeth to strip a wire. The point, rather, is that the fact that there is a better way than using my teeth to strip a wire cannot establish that, in general, I ought not to use my teeth for that purpose. For, in any given situation, it might be that the better way (using a wire stripper) is not available to me, in which case the unavailable possibility of the better way would not be a relevant consideration in my deliberations about what to do.</p>
<p>Just as the possibility of stripping the wire using the superior method is not enough to establish that in general one ought not use one’s teeth for that purpose, so the proponent of the dominance-based argument cannot hope to establish that one ought to avoid a belief state by just pointing to the fact that there is some state which dominates it. The existence of this dominant state would be relevant to one’s deliberations about what to believe <em>only if</em> it is available for the agent to rationally switch to.</p>
<p>If this is right, then we can’t strengthen (ND) by dropping the availability requirement. Admittedly, I’ve said very little about this notion of ‘availability’, but note that all that is needed to block the argument from (a) and (ND) to the conclusion that <span class="math inline"><em>s</em><sub>1</sub></span> is irrational is that the set of states which are <em>available</em> to the agent be a proper subset of the set of all possible states. For, supposing that there is a state defined over the same set of propositions which is guaranteed to do better than <span class="math inline"><em>s</em><sub>1</sub></span>, we get the conclusion through (ND) that <span class="math inline"><em>s</em><sub>1</sub></span> is irrational only if we can also assume that the dominant state is among those that are available for the agent switch to. But as long as the set of available states is a proper subset of the set of all possible states, we cannot assume that and therefore the argument fails.</p>
<h1 id="OO">Conclusion</h1>
<p>In this paper, I’ve argued against two versions of the view that wants to explain the normativity of structural, deductive coherence norms in terms of <em>the aim of truth</em>. According to the first version, we must avoid deductively incoherent states because doing so guarantees having an inaccurate attitude. Following a well-established tradition, I’ve argued that the Preface cases are enough to show that this idea is too strong. The second version, avoids this charge by opting for a <em>comparative</em> criterion of irrationality: i.e., that a state is irrational if there is another state the agent can switch to which does better with respect to accurately representing the world. However, I argued that this version is <em>too</em> weak: even when restricted to 2-premise arguments, it fails to count all cases of deductive incoherence as irrational.</p>
<p>Where does this leave us with respect to the question of the source of the normativity of logic? There are two options that remain open, which I would like to quickly sketch before closing. The first option is the ‘evidentialist’ view put forward originally by Niko Kolodny, which seeks to reject the very idea that there are any structural, deductive norms of coherence. According to the evidentialist proposal, the apparent normativity of logic can be explained by our <em>responsiveness to reasons</em>. In a nutshell, the idea is that someone who believes the premises of a valid argument and disbelieves its conclusion is failing to respond correctly to her reasons: Either she fails to see the reason against the premises or those in favor of the conclusion. In either case, what’s bad about being incoherent is not that one violates some norm or principle; rather, the problem is with her responsiveness to reasons.</p>
<p>The evidentialist proposal can be viewed as a version of the extrinsic view in that it accepts the first component of the view — that logical validity is to be defined independently of our doxastic lives — and only slightly tweaks the second: The <em>apparent</em> coherence norms are vindicated by showing that following them contributes to the aim of having true beliefs and avoiding false ones.</p>
<p>The second option represents a much more radical departure. It rejects the very idea that logic is to be understood independently of our doxastic lives. According to this view, the normativity of logic is <em>intrinsic</em> to it as logic itself is a normative enterprise. One way of developing the intrinsic view is along broadly Kantian lines by claiming that logic is in the business of laying out (formally — in a sense of ‘formal’ to be clarified) the norms that <em>constitutively</em> govern belief and doxastic reasoning more generally.</p>
<p>Needless to say, there is much more to say about each of these options and I want to remain completely neutral between them here. I hope to return to both options in future work.</p>
<h1 class="unnumbered" id="acknowledgements">acknowledgements</h1>
<p>I wish to thank Fabrizio Cariani, Reza Hadisi, Tom Lockhart, Will Small, Julia Staffel, Daniel Sutherland, and Brian Talbot for helpful comments and suggestion on earlier versions. Thanks also to the audiences at Epistemology of Reasoning conference at the University of Cologne, Logic Rulez?! conference at Wiener Forum für Analytische Philosophie, APA Central, the Society of Exact Sciences Conference at University of Connecticut, University of Illinois’ Brown bag talks series, and two anonymous referees.</p>
<div id="refs" class="references hanging-indent" role="doc-bibliography">
<div id="ref-kolodny2005">
<p>Kolodny, Niko. 2005. “Why Be Rational?” <em>Mind</em> 114 (455): 509–63. <a href="https://doi.org/10.1093/mind/fzi509">https://doi.org/10.1093/mind/fzi509</a>.</p>
</div>
<div id="ref-macfarlane2004">
<p>MacFarlane, John. 2004. “In What Sense (If Any) Is Logic Normative for Thought.” <em>Unpublished Manuscript</em>, 1–25.</p>
</div>
<div id="ref-tarski2002">
<p>Tarski, Alfred. 2002. “On the Concept of Following Logically.” <em>History and Philosophy of Logic</em> 23 (3): 155–96. <a href="https://doi.org/10.1080/0144534021000036683">https://doi.org/10.1080/0144534021000036683</a>.</p>
</div>
</div>
</body>
</html>
